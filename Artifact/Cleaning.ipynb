{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Games\n",
    "HockeyReference : https://www.hockey-reference.com/ \\\n",
    "All games since 1980 avaible as csv - No actual scraping required"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Games Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pandas library as pd\n",
    "import pandas as pd\n",
    "\n",
    "# Read the csv file \"Regular Season Games.txt\" into a pandas DataFrame called \"df\"\n",
    "df = pd.read_csv(\"Regular Season Games.txt\")\n",
    "\n",
    "# Drop the 5th, 6th, 7th, and 8th columns of the DataFrame\n",
    "df = df.drop(df.columns[[5, 6, 7, 8]], axis=1)\n",
    "\n",
    "# Create a new column called \"Winner\" that contains the name of the winning team\n",
    "# If the \"G\" column is greater than the \"G.1\" column, the winner is the \"Visitor\"\n",
    "# If the \"G\" column is less than the \"G.1\" column, the winner is the \"Home\"\n",
    "# If the \"G\" column is equal to the \"G.1\" column, the winner is considered a tie\n",
    "df['Winner'] = df.apply(lambda x: x['Visitor'] if x['G'] > x['G.1'] else (x['Home'] if x['G'] < x['G.1'] else 'Tie'), axis=1)\n",
    "\n",
    "# Filter out any rows where the winner is a tie\n",
    "df = df[df['Winner'] != 'Tie']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the datetime module from the Python standard library\n",
    "from datetime import datetime\n",
    "\n",
    "# Define a function called \"closest_year\" that takes a string in the format \"YYYY-MM-DD\" as input\n",
    "def closest_year(date_str):\n",
    "    # Convert the string into a datetime object using the strptime method\n",
    "    date = datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "    \n",
    "    # Check if the month of the datetime object is less than 7 (July)\n",
    "    if date.month < 7:\n",
    "        # If it is, return the year of the datetime object\n",
    "        return date.year\n",
    "    else:\n",
    "        # If it isn't, return the year of the datetime object plus one\n",
    "        return date.year + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column \"Date\" in the DataFrame \"df\" by applying the function \"closest_year\" to each row along the axis 1 (columns)\n",
    "df['Season'] = df.apply(lambda x: closest_year(x['Date']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Season'] != 1995]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standings\n",
    "NHL.Com : https://www.nhl.com/ \\\n",
    "Standings from seasons from 1993 - 2022 : Available as csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in Home and Away Stats for Each time in Every Game"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Consistent Column Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the csv file \"Standings.csv\" into a pandas DataFrame called \"df1\"\n",
    "df1 = pd.read_csv(\"Standings.csv\")\n",
    "\n",
    "# Create a new column \"Season\" by taking the modulo of each value in the \"Season\" column with 10000\n",
    "df1['Season'] =  df1['Season'] % 10000\n",
    "\n",
    "\n",
    "df1 = df1.drop(columns=[\"FOW%\", \"OT\", \"T\"])\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing With Naming Convention Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper\n",
    "def replace_value(x):\n",
    "    if isinstance(x, str) and x == \"Montréal Canadiens\":\n",
    "        x = x.replace(\"Montréal Canadiens\", \"Montreal Canadiens\")\n",
    "        return x\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "df1 = df1.applymap(replace_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper\n",
    "def replace_value(x):\n",
    "    if isinstance(x, str) and x == \"Winnipeg Jets (1979)\":\n",
    "        x = x.replace(\"Winnipeg Jets (1979)\", \"Winnipeg Jets\")\n",
    "        return x\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "df1 = df1.applymap(replace_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "mask = df1['Season'] <= 2004\n",
    "\n",
    "df1['Team'] = np.where(mask, df1['Team'].str.replace(\"Anaheim Ducks\", \"Mighty Ducks of Anaheim\"), df1['Team'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Merged Dataframe with Home and Visitor Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the dataframes\n",
    "merged_df1 = pd.merge(df, df1, left_on=['Season', 'Visitor'], right_on=['Season', 'Team'])\n",
    "\n",
    "# rename the columns from the other dataframe\n",
    "merged_df1 = merged_df1.rename(columns={'GP': 'v_GP', 'W': 'v_W', 'L': 'v_L', 'P': 'v_P', 'P%': 'v_P%', 'RW': 'v_RW', 'ROW': 'v_ROW', 'S/O Win': 'v_S/O Win', 'GF': 'v_GF', 'GA': 'v_GA', 'GF/GP': 'v_GF/GP', 'GA/GP': 'v_GA/GP', 'PP%': 'v_PP%', 'PK%': 'v_PK%', 'Net PP%': 'v_Net PP%', 'Net PK%': 'v_Net PK%', 'Shots/GP': 'v_Shots/GP', 'SA/GP': 'v_SA/GP'})\n",
    "\n",
    "\n",
    "# merge the dataframes again\n",
    "merged_df2 = pd.merge(merged_df1, df1, left_on=['Season', 'Home'], right_on=['Season', 'Team'])\n",
    "\n",
    "# rename the columns from the other dataframe\n",
    "merged_df2 = merged_df2.rename(columns={'GP': 'h_GP', 'W': 'h_W', 'L': 'h_L', 'P': 'h_P', 'P%': 'h_P%', 'RW': 'h_RW', 'ROW': 'h_ROW', 'S/O Win': 'h_S/O Win', 'GF': 'h_GF', 'GA': 'h_GA', 'GF/GP': 'h_GF/GP', 'GA/GP': 'h_GA/GP', 'PP%': 'h_PP%', 'PK%': 'h_PK%', 'Net PP%': 'h_Net PP%', 'Net PK%': 'h_Net PK%', 'Shots/GP': 'h_Shots/GP', 'SA/GP': 'h_SA/GP'})\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Cleaning Touches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = merged_df2.drop(columns = ['Visitor', 'Home'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.rename(columns = {'G' : 'v_goals', 'G.1' : 'h_goals', 'Team_x' : 'Visitor', 'Team_y' : 'Home', 'Season_x' : 'Season'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.sort_values('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"ArtifactDataset\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aaf89b8e18e8001388ae5f602fac2560202aca3fdca6dcc84ec365eaf6a69bd8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
